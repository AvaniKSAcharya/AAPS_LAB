{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.3.1"
    },
    "colab": {
      "name": "AML5201_MultivariateOutlierDetection_R.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_0IeRbLGWjA"
      },
      "source": [
        "**Install packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLeB1yyiGTUJ"
      },
      "source": [
        "# Package for ggplot2 enhancements\n",
        "install.packages(\"ggExtra\")\n",
        "\n",
        "# Package for multivariate normal distribution\n",
        "install.packages('mvtnorm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBwU1D1ib2o6"
      },
      "source": [
        "**Load essential libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DhQTLweb138"
      },
      "source": [
        "library(ggplot2) # library for plotting\n",
        "library(dplyr) # library for data wrangling\n",
        "library(ggExtra) # library for enhanced ggplot2 plots\n",
        "library(mvtnorm) # library for multivariate normal distribution\n",
        "library(tidyr) # library to reorganize data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NfALqh66Jy0"
      },
      "source": [
        "# Load RData file data2.RData\n",
        "load(url('https://tinyurl.com/527nxn23'))\n",
        "str(data2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7KbwXXcK9lQ"
      },
      "source": [
        "# Training data\n",
        "X_train = data2$X # training data as matrix (all samples here are non-anomalous)\n",
        "df_train = as.data.frame(X_train) # training data frame\n",
        "head(X_train, n = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHS_Ch7WLYE_"
      },
      "source": [
        "# Validation data\n",
        "X_validate = data2$Xval # validation data as matrix\n",
        "y_validate = data2$yval # validation data labels\n",
        "df_validate = as.data.frame(X_validate) # validation data frame\n",
        "head(y_validate, n = 5) # 1 represents an outlier sample, 0 represents a regular sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_3Xh3TUL_gQ"
      },
      "source": [
        "# Fraction of servers that are outliers in the validation set\n",
        "mean(y_? = ?)  # supervised algorithms have to address such class imbalance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw3ZnpYB8fCG"
      },
      "source": [
        "# Wide to long dataframe containing training data\n",
        "df_gather_train = gather(as.data.frame(X_train))\n",
        "colnames(df_gather_train) = c('Variable', 'Value')\n",
        "head(df_gather_train, n = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNVOUaLvMpMA"
      },
      "source": [
        "# Wide to long dataframe containing validation data\n",
        "df_gather_validate = gather(as.data.frame(X_validate))\n",
        "colnames(df_gather_validate) = c('Variable', 'Value')\n",
        "head(df_gather_validate, n = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA7ylAiPNEFR"
      },
      "source": [
        "# Separate density plots for each variable (or features) in the training data\n",
        "df_gather_train %>% ggplot(aes(x = ?, fill = ?, color = ?)) +\n",
        "geom_density(alpha = 0.3)+ggtitle('Distibution of variables from training data')\n",
        "\n",
        "# Which variable appears the least normally disributed?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67NCmd8L9AkD"
      },
      "source": [
        "# Separate density plots for each variable (or features) in the validation data\n",
        "df_gather_validate %>% ggplot(aes(x = Value, fill = Variable, color = Variable)) +\n",
        "geom_density(alpha = 0.3)+ggtitle('Distibution of variables from validation data')\n",
        "\n",
        "# Which variable appears the least normally disributed?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6hhUDJCNazV"
      },
      "source": [
        "# Make a scatter plot with the marginal densities for any pair of variables\n",
        "# in the training data\n",
        "\n",
        "p1 = ggplot(data = ?, aes(x = ?, y = ?)) + \n",
        "geom_point(size = 2, alpha = 0.7) + xlab(\"Variable-1\") + \n",
        "   ylab(\"Variable-5\") + ggtitle(\"Scatter Plot\") +\n",
        "   coord_fixed(ratio = 1) +\n",
        "   stat_ellipse(level = 0.68, color = 'red')+\n",
        "   stat_ellipse(level = 0.95, color = 'green')+\n",
        "   stat_ellipse(level = 0.997, color = 'blue')\n",
        "\n",
        "# Add marginal histogram plot to the scatter plot \n",
        "delta =1\n",
        "ggMarginal(p1, type = 'histogram', color = 'black', binwidth = delta)\n",
        "\n",
        "# Add marginal density plot to the scatter plot\n",
        "ggMarginal(p1, type = 'density', color = 'cyan')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solve(cov(as.data.frame(cbind(X_train, 2*X_train[, 11]))))"
      ],
      "metadata": {
        "id": "Qt_rO5iac7Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiiqXXP-NruT"
      },
      "source": [
        "## Build model using training data \n",
        "mu_train = mean(?) # sample mean using training data\n",
        "S_train = ?(as.data.frame(X_train)) # sample covariance matrix using training data\n",
        "S_train_inverse = solve(?)  # inverse of sample covariance matrix from training data\n",
        "\n",
        "# Mahalanobis distance of training samples\n",
        "M_distance_train = apply(?, 1, function(x){sqrt(t(x-?) %*% ? %*% (?-mu_train))})\n",
        "\n",
        "# Mahalanobis distance of validation samples using model built using training data\n",
        "M_distance_validate = apply(?, 1, function(x){sqrt(t(x-mu_train) %*% ? %*% (x-mu_train))})\n",
        "\n",
        "# Add Mahalanobis distance as new column of training and validation data frame\n",
        "df_train$MD = ?\n",
        "df_validate$? = M_distance_validate\n",
        "\n",
        "head(df_validate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h94T0U7mOCYX"
      },
      "source": [
        "## Determine cutoff probability such that we get the best performance on the validation set\n",
        "## Best performance corresponds to, for example, the best F1 score (close to 1)\n",
        "\n",
        "# Add a new column to training and validation data frame for outliers\n",
        "k = ncol(X_train) # dimensions or the number of features\n",
        "j = 5 # vary this to change cutoff probability\n",
        "cutoff_probability = 1-(10^(-j))\n",
        "threshold = qchisq(?, ?) # threshold for Mahalanobis distance\n",
        "df_train$Outliers = ((?)^2 >= threshold)\n",
        "df_validate$Outliers = ((df_validate$MD)^2 >= ?)\n",
        "\n",
        "# True positives\n",
        "tp = sum((df_validate$Outliers == 'TRUE') & (y_validate == 1))\n",
        "# False positives\n",
        "fp = sum((df_validate$Outliers == 'TRUE') & (y_validate == 0))\n",
        "# False negatives\n",
        "fn = sum((df_validate$Outliers == 'FALSE') & (y_validate == 1))\n",
        "# Precision\n",
        "precision = tp / (tp + fp)\n",
        "# Recall\n",
        "recall = tp / (tp + fn)\n",
        "# F1 score\n",
        "F1 = (2 * precision * recall) / (precision + recall)\n",
        "cat(sprintf('Threshold = %f\\n', threshold))\n",
        "cat(sprintf('For probability cutoff = %f, \\nPrecision = %f,\\nRecall = %f,\\nF1 score = %f,\\nFraction of outliers in training data = %f\\n', cutoff_probability, precision, recall, F1,mean(df_train$Outliers == 'TRUE')))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}